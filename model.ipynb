{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curiculum Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic\n",
    "\n",
    "df = get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in the `age` column.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['pclass','age','fare','sibsp','parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept of the model\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability of a passenger surviving, using the training data\n",
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision, Recall, F1-score, and Support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curiculum model = 64% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Baseline calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df\n",
    "tdf = get_titanic_data()\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prep_titanic(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# died is the majority response - requires human intervention, but gives same result as Ryan's\n",
    "# positive case = died\n",
    "my_baseline_accuracy = 307/(307+190)\n",
    "my_baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ryan's method - can be automated to function\n",
    "train['baseline_prediction'] = 0\n",
    "pd.crosstab(train.baseline_prediction, train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = (train.baseline_prediction == train.survived).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline accuracy = 62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the question to mean: create a model that has age, fare, and pclass as only features\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train.drop(columns=['low_tip_target'])\n",
    "# y_train = train.low_tip_target\n",
    "\n",
    "# X_validate = validate.drop(columns=['low_tip_target'])\n",
    "# y_validate = validate.low_tip_target\n",
    "\n",
    "# X_test = test.drop(columns=['low_tip_target'])\n",
    "# y_test = test.low_tip_target\n",
    "\n",
    "X_train_afp = train.drop(columns=['baseline_prediction', 'survived', 'sex_male', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_train_afp = train.survived\n",
    "\n",
    "X_validate_afp = validate.drop(columns=['survived', 'sex_male', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_validate_afp = validate.survived\n",
    "\n",
    "X_test_afp = test.drop(columns=['survived', 'sex_male', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_test_afp = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_afp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_afp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit to X_train, y_train for the attributes age, fare, pclass only\n",
    "logit_afp = logit.fit(X_train_afp, y_train_afp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_afp.coef_)\n",
    "\n",
    "\n",
    "print(logit_afp.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_afp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values on X_train.\n",
    "y_pred_afp = logit_afp.predict(X_train_afp)\n",
    "y_pred_proba_afp = logit_afp.predict_proba(X_train_afp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model age, fare, pclass accuracy\n",
    "logit_afp.score(X_train_afp, y_train_afp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_train_afp, y_pred_afp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for Model afp\n",
    "print(classification_report(y_train_afp, y_pred_afp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model using age, fare, and pclass only has a 71% accuracy rating. \n",
    "Age in this model was filled using imputed values.  \n",
    "\n",
    "Accuracy:   \n",
    "So this model performs better than the 61% baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Include sex in your model as well. Note that you'll need to encode this feature before including it in a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the question to mean: create a model that has sex, age, fare, and pclass as features\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train.drop(columns=['low_tip_target'])\n",
    "# y_train = train.low_tip_target\n",
    "\n",
    "# X_validate = validate.drop(columns=['low_tip_target'])\n",
    "# y_validate = validate.low_tip_target\n",
    "\n",
    "# X_test = test.drop(columns=['low_tip_target'])\n",
    "# y_test = test.low_tip_target\n",
    "\n",
    "X_train_safp = train.drop(columns=['baseline_prediction', 'survived', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_train_safp = train.survived\n",
    "\n",
    "X_validate_safp = validate.drop(columns=['survived', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_validate_safp = validate.survived\n",
    "\n",
    "X_test_safp = test.drop(columns=['survived', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_test_safp = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_safp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit to X_train, y_train for the attributes age, fare, pclass only\n",
    "logit_safp = logit.fit(X_train_safp, y_train_safp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_safp.coef_)\n",
    "\n",
    "\n",
    "print(logit_safp.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_safp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values on X_train.\n",
    "y_pred_safp = logit_safp.predict(X_train_safp)\n",
    "y_pred_proba_safp = logit_safp.predict_proba(X_train_safp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sex, age, fare, pclass accuracy\n",
    "logit_safp.score(X_train_safp, y_train_safp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model using sex, age, fare, and pclass only has a 79% accuracy rating.  \n",
    "Age in this model was filled using imputed values.  \n",
    "\n",
    "Accuracy:   \n",
    "So this model performs better than the 61% baseline and better than the model without sex which was 71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model pclass as only attribute\n",
    "X_train_p = train.drop(columns=['baseline_prediction', 'survived', 'age', 'fare', 'sex_male', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_train_p = train.survived\n",
    "\n",
    "X_validate_p = validate.drop(columns=['survived', 'age', 'fare', 'sex_male',  'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_validate_p = validate.survived\n",
    "\n",
    "X_test_p = test.drop(columns=['survived', 'age', 'fare', 'sex_male',  'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_test_p = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify pclass is only attribute\n",
    "X_train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit to X_train, y_train for the attribute pclass only\n",
    "logit_p = logit.fit(X_train_p, y_train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_p.coef_)\n",
    "print(logit_p.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values on X_train.\n",
    "y_pred_p = logit_p.predict(X_train_p)\n",
    "y_pred_proba_p = logit_p.predict_proba(X_train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sex, age, fare, pclass accuracy\n",
    "logit_p.score(X_train_p, y_train_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model using pclass only has a 68% accuracy rating.  \n",
    "Accuracy:   \n",
    "Baseline = 61%  \n",
    "Age, Fare, pclass = 71%  \n",
    "Sex, Age, Fare, pclass = 79%  \n",
    "pclass = 68%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model age as only attribute\n",
    "X_train_a = train.drop(columns=['baseline_prediction', 'survived', 'pclass', 'fare', 'sex_male', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_train_a = train.survived\n",
    "\n",
    "X_validate_a = validate.drop(columns=['survived', 'pclass', 'fare', 'sex_male',  'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_validate_a = validate.survived\n",
    "\n",
    "X_test_a = test.drop(columns=['survived', 'pclass', 'fare', 'sex_male',  'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_test_a = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify age is only attribute\n",
    "X_train_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit to X_train, y_train for the attribute age only\n",
    "logit_a = logit.fit(X_train_a, y_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_a.coef_)\n",
    "print(logit_a.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model age accuracy\n",
    "logit_a.score(X_train_a, y_train_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model using age only has a 61% accuracy rating. Which matches the baseline.  \n",
    "Age in this model was filled using imputed values.  \n",
    "\n",
    "Accuracy:   \n",
    "Baseline = 61%  \n",
    "Age, Fare, pclass = 71%  \n",
    "Sex, Age, Fare, pclass = 79%  \n",
    "pclass = 68%    \n",
    "Age = 61%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model sex as only attribute\n",
    "X_train_s = train.drop(columns=['baseline_prediction', 'survived', 'pclass', 'fare', 'age', 'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_train_s = train.survived\n",
    "\n",
    "X_validate_s = validate.drop(columns=['survived', 'pclass', 'fare', 'age',  'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_validate_s = validate.survived\n",
    "\n",
    "X_test_s = test.drop(columns=['survived', 'pclass', 'fare', 'age',  'alone', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_test_s = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify sex_male is only attribute\n",
    "X_train_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit to X_train, y_train for the attribute sex_male only\n",
    "logit_s = logit.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_s.coef_)\n",
    "print(logit_s.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sex_male accuracy\n",
    "logit_s.score(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model using sex_male only has a 78% accuracy rating.  \n",
    "Accuracy:   \n",
    "Baseline = 61%  \n",
    "Age, Fare, pclass = 71%  \n",
    "Sex, Age, Fare, pclass = 79%  \n",
    "pclass = 68%    \n",
    "Age = 61%  \n",
    "sex_male = 78%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model alone as only attribute\n",
    "X_train_al = train.drop(columns=['baseline_prediction', 'survived', 'pclass', 'fare', 'age', 'sex_male', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_train_al = train.survived\n",
    "\n",
    "X_validate_al = validate.drop(columns=['survived', 'pclass', 'fare', 'age',  'sex_male', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_validate_al = validate.survived\n",
    "\n",
    "X_test_al = test.drop(columns=['survived', 'pclass', 'fare', 'age',  'sex_male', 'sibsp', 'parch', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "y_test_al = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify alone is only attribute\n",
    "X_train_al.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit to X_train, y_train for the attribute alone only\n",
    "logit_al = logit.fit(X_train_al, y_train_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_al.coef_)\n",
    "print(logit_al.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model alone accuracy\n",
    "logit_al.score(X_train_al, y_train_al)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model using alone only has a 64% accuracy rating.  \n",
    "Accuracy:   \n",
    "Baseline = 61%  \n",
    "Age, Fare, pclass = 71%  \n",
    "Sex, Age, Fare, pclass = 79%  \n",
    "pclass = 68%    \n",
    "Age = 61%  \n",
    "sex_male = 78%  \n",
    "alone = 64%  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Choose you best model and evaluate it on the test dataset. Is it overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editing this question to add validate step. Validate on 2 best models = sex_male only and sex, age, fare, pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sex, age, fare, pclass validate data\n",
    "print(\"model_safp\\n\", logit_safp.score(X_validate_safp, y_validate_safp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sex_male validate accuracy\n",
    "logit_s.score(X_validate_s, y_validate_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on perfomance on the validate data, conclude model with sex, age, fare, and pclass performs the best.  \n",
    "Run that on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sex, age, fare, pclass validate data\n",
    "print(\"model_safp\\n\", logit_safp.score(X_test_safp, y_test_safp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for this model is 80% on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Bonus How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Bonus: How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Bonus: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "C\n",
    "=\n",
    ".01\n",
    ",\n",
    ".1\n",
    ",\n",
    "1\n",
    ",\n",
    "10\n",
    ",\n",
    "100\n",
    ",\n",
    "1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Bonus: how does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decission Tree model exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df\n",
    "tdf = get_titanic_data()\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prep_titanic(tdf)\n",
    "print(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline accuracy determination would be the same as logistic regression baseline -- correct?\n",
    "train.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decission tree object\n",
    "# per lesson reccomended to use max_depth=3 for 1st model\n",
    "clf1 = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted y values and probabilities\n",
    "y_pred1 = clf1.predict(X_train)\n",
    "y_pred_proba1 = clf1.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "clf1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "confusion_matrix(y_train, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better visual of confusion matrix as dataframe\n",
    "# 0: died, 1: survived\n",
    "labels = sorted(y_train.unique())\n",
    "\n",
    "matrix1 = pd.DataFrame(confusion_matrix(y_train, y_pred1), index=labels, columns=labels)\n",
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy=\", clf1.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Model 1\\nPostive=Died\")\n",
    "matrix1 = matrix1.rename(columns={0: 'Died', 1: 'Survived'})\n",
    "matrix1 = matrix1.rename(index={0: 'Died', 1: 'Survived'})\n",
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Positive=\", matrix1.Died[0])\n",
    "print(\"True Negative=\", matrix1.Survived[1])\n",
    "print(\"False Positive=\", matrix1.Died[1])\n",
    "print(\"False Negative=\", matrix1.Survived[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report Model 1\")\n",
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2nd model will use max_depth=10\n",
    "# create the decission tree object\n",
    "clf2 = DecisionTreeClassifier(max_depth=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted y values and probabilities\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred_proba2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "model2cm = confusion_matrix(y_train, y_pred2)\n",
    "model2cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better visual of confusion matrix as dataframe\n",
    "# 0: died, 1: survived\n",
    "labels = sorted(y_train.unique())\n",
    "\n",
    "matrix2 = pd.DataFrame(confusion_matrix(y_train, y_pred2), index=labels, columns=labels)\n",
    "print(\"Confusion Matrix Model 2\\nPostive=Died\")\n",
    "matrix2 = matrix2.rename(columns={0: 'Died', 1: 'Survived'})\n",
    "matrix2 = matrix2.rename(index={0: 'Died', 1: 'Survived'})\n",
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Positive=\", matrix2.Died[0])\n",
    "print(\"True Negative=\", matrix2.Survived[1])\n",
    "print(\"False Positive=\", matrix2.Died[1])\n",
    "print(\"False Negative=\", matrix2.Survived[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "print(\"Model 2\\nAccuracy=\", clf2.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report Model 2\")\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 3rd model will use max_depth=1\n",
    "# create the decission tree object\n",
    "clf3 = DecisionTreeClassifier(max_depth=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted y values and probabilities\n",
    "y_pred3 = clf3.predict(X_train)\n",
    "y_pred_proba3 = clf3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "model3cm = confusion_matrix(y_train, y_pred3)\n",
    "model3cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better visual of confusion matrix as dataframe\n",
    "# 0: died, 1: survived\n",
    "labels = sorted(y_train.unique())\n",
    "\n",
    "matrix3 = pd.DataFrame(confusion_matrix(y_train, y_pred3), index=labels, columns=labels)\n",
    "print(\"Confusion Matrix Model 3\\nPostive=Died\")\n",
    "matrix3 = matrix3.rename(columns={0: 'Died', 1: 'Survived'})\n",
    "matrix3 = matrix3.rename(index={0: 'Died', 1: 'Survived'})\n",
    "matrix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy score\n",
    "print(\"Model 3\\nAccuracy=\", clf3.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report Model 3\")\n",
    "print(classification_report(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 with a max_depth=10 has the highest accuracy, however, it is probably overfit.  \n",
    "Will test Model 1 and 2 both on validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 fit validate\n",
    "# fit the model\n",
    "clf1 = clf1.fit(X_validate, y_validate)\n",
    "# get accuracy score\n",
    "print(\"Model 1\\nAccuracy=\", clf1.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 fit validate\n",
    "# fit the model\n",
    "clf2v = clf2.fit(X_validate, y_validate)\n",
    "# get accuracy score\n",
    "print(\"Model 2\\nAccuracy=\", clf2v.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted y values and probabilities\n",
    "y_pred2v = clf2v.predict(X_validate)\n",
    "y_pred_proba2v = clf2v.predict_proba(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "model2cmv = confusion_matrix(y_validate, y_pred2v)\n",
    "model2cmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 fit test\n",
    "# fit the model\n",
    "clf2t = clf2.fit(X_test, y_test)\n",
    "# get accuracy score\n",
    "print(\"Model 2\\nAccuracy=\", clf2t.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted y values and probabilities\n",
    "y_pred2t = clf2t.predict(X_test)\n",
    "y_pred_proba2t = clf2t.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "model2cmt = confusion_matrix(y_test, y_pred2t)\n",
    "model2cmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results indicate best performing model is with a max_depth=10 and that this model is not over fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=10, random_state=123)\n",
    "clf2.fit(X_train, y_train)\n",
    "dot_data = export_graphviz(clf2, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanicm2_decision_tree', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get labels on graphviz\n",
    "# dot_data = export_graphviz(clf2, feature_names= X.columns, class_names= {0:'not survived', 1:'survived'}, rounded=True, filled=True, out_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df\n",
    "tdf = get_titanic_data()\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prep_titanic(tdf)\n",
    "print(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline accuracy determination would be the same as logistic regression baseline -- correct?\n",
    "train.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf20 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=20, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf20 = rf20.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf20 = rf20.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandomForest20 Accuracy=\", rf20.score(X_train, y_train))\n",
    "print(\"Confusion Matrix rf20\\n\", confusion_matrix(y_train, y_predrf20))\n",
    "print(\"Classification Report rf20\\n\", classification_report(y_train, y_predrf20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAKEAWAY: if \"0\" is positive case use row \"0\" for recall and precission.   \n",
    "# if \"1\" is positive case use row \"1\" for recall and procission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "#tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusionrf20 = confusion_matrix(y_train, y_predrf20)\n",
    "print(\"Confusion Matrix rf20\\n\",confusionrf20, \"\\n\")\n",
    "#[row, column]\n",
    "TP = confusionrf20[1, 1]\n",
    "TN = confusionrf20[0, 0]\n",
    "FP = confusionrf20[0, 1]\n",
    "FN = confusionrf20[1, 0]\n",
    "print(\"True Positive (count where predicted 1 and actually 1):\", TP)\n",
    "print(\"True Negative (count where predicted 0 and actually 0):\", TN)\n",
    "print(\"False Positive (count where predicted 1(survived) and actually 0(died)):\", FP)\n",
    "print(\"False Negative (count where predicted 0(died) and actually 1(survived)):\", FN, \"\\n\")\n",
    "print(\"Calculated Precision (TP/TP+FP):\", round(TP/(TP+FP), 2))\n",
    "print(\"Calculated Recall (TP/TP+FN):\", round(TP/(TP+FN), 2), \"\\n\")\n",
    "print(\"Classification Report rf20\\n\", classification_report(y_train, y_predrf20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Random Forest TRAIN resluts for max_depth=20, min_samples_leaf=1, n_estimators=100)   \n",
    "Accuracy = 98.6%   \n",
    "see classifiation report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=5,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "\n",
    "rf3 = rf3.fit(X_train, y_train)\n",
    "\n",
    "y_predrf3 = rf3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandomForest3 Accuracy=\", rf3.score(X_train, y_train), \"\\n\")\n",
    "print(\"Confusion Matrix rf3\\n\", confusion_matrix(y_train, y_predrf3), \"\\n\")\n",
    "print(\"Classification Report rf3\\n\", classification_report(y_train, y_predrf3), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Depth = 20 gives much better accuracy on in sample data, but is likely to be overfit   \n",
    "A max depth of 3 gives less accuaracy but is more likely to not be over fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 10) (214, 10) (178, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic\n",
    "\n",
    "\n",
    "\n",
    "# split df\n",
    "tdf = get_titanic_data()\n",
    "tdf.head()\n",
    "\n",
    "train, validate, test = prep_titanic(tdf)\n",
    "print(train.shape, validate.shape, test.shape)\n",
    "\n",
    "# Baseline accuracy determination would be the same as logistic regression baseline -- correct?\n",
    "train.survived.value_counts(normalize=True)\n",
    "\n",
    "train.head()\n",
    "\n",
    "# split X and y\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNN Object\n",
    "\n",
    "# weights = ['uniform', 'density']\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "knn5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predknn5 = knn5.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn5 Accuracy= 0.7766599597585513 \n",
      "\n",
      "Confusion Matrix knn5\n",
      " [[255  52]\n",
      " [ 59 131]] \n",
      "\n",
      "Classification Report knn5\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       307\n",
      "           1       0.72      0.69      0.70       190\n",
      "\n",
      "    accuracy                           0.78       497\n",
      "   macro avg       0.76      0.76      0.76       497\n",
      "weighted avg       0.78      0.78      0.78       497\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"knn5 Accuracy=\", knn5.score(X_train, y_train), \"\\n\")\n",
    "print(\"Confusion Matrix knn5\\n\", confusion_matrix(y_train, y_predknn5), \"\\n\")\n",
    "print(\"Classification Report knn5\\n\", classification_report(y_train, y_predknn5), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### see above reports, use the classication report for precission and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNN Object\n",
    "\n",
    "# weights = ['uniform', 'density']\n",
    "knn10 = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# Fit the model to the training data\n",
    "knn10.fit(X_train, y_train)\n",
    "\n",
    "y_predknn10 = knn10.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn10 Accuracy= 0.7645875251509054 \n",
      "\n",
      "Confusion Matrix knn10\n",
      " [[283  24]\n",
      " [ 93  97]] \n",
      "\n",
      "Classification Report knn10\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       307\n",
      "           1       0.80      0.51      0.62       190\n",
      "\n",
      "    accuracy                           0.76       497\n",
      "   macro avg       0.78      0.72      0.73       497\n",
      "weighted avg       0.77      0.76      0.75       497\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"knn10 Accuracy=\", knn10.score(X_train, y_train), \"\\n\")\n",
    "print(\"Confusion Matrix knn10\\n\", confusion_matrix(y_train, y_predknn10), \"\\n\")\n",
    "print(\"Classification Report knn10\\n\", classification_report(y_train, y_predknn10), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNN Object\n",
    "\n",
    "# weights = ['uniform', 'density']\n",
    "knn20 = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# Fit the model to the training data\n",
    "knn20.fit(X_train, y_train)\n",
    "\n",
    "y_predknn20 = knn20.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn20 Accuracy= 0.7645875251509054 \n",
      "\n",
      "Confusion Matrix knn20\n",
      " [[278  29]\n",
      " [111  79]] \n",
      "\n",
      "Classification Report knn20\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80       307\n",
      "           1       0.73      0.42      0.53       190\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.72      0.66      0.66       497\n",
      "weighted avg       0.72      0.72      0.70       497\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"knn20 Accuracy=\", knn10.score(X_train, y_train), \"\\n\")\n",
    "print(\"Confusion Matrix knn20\\n\", confusion_matrix(y_train, y_predknn20), \"\\n\")\n",
    "print(\"Classification Report knn20\\n\", classification_report(y_train, y_predknn20), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN5 performs best on training data, only slightly higher accuracy than knn10 or knn20, but better recall and precission than the other 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n",
    "\n",
    "For both the iris and the titanic data,\n",
    "\n",
    "Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually).\n",
    "Create a new dataframe with top 4 features.\n",
    "Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features).\n",
    "Run your final model on your out-of-sample dataframe (test_df). Evaluate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irirs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "\n",
    "Titanic Data\n",
    "Create a feature named who, this should be either man, woman, or child. How does including this feature affect your model's performance?\n",
    "Create a feature named adult_male that is either a 1 or a 0. How does this affect your model's predictions?\n",
    "Iris Data\n",
    "Create features named petal_area and sepal_area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
